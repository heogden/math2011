<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>MATH2011: Statistical Distribution Theory</title>
  <meta name="description" content="The course notes for MATH2011: Statistical Distribution Theory." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="MATH2011: Statistical Distribution Theory" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The course notes for MATH2011: Statistical Distribution Theory." />
  <meta name="github-repo" content="heogden/math2011" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="MATH2011: Statistical Distribution Theory" />
  
  <meta name="twitter:description" content="The course notes for MATH2011: Statistical Distribution Theory." />
  

<meta name="author" content="Dr Helen Ogden" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  

<link rel="next" href="moments.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH2011: Statistical Distribution Theory</a></li>

<li class="divider"></li>
<li class="part"><span><b>I Distributions and their properties</b></span></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Probability distributions</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#random-variables"><i class="fa fa-check"></i><b>1.1</b> Random variables</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#examples-of-discrete-distributions"><i class="fa fa-check"></i><b>1.2</b> Examples of discrete distributions</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#the-bernoulli-distribution"><i class="fa fa-check"></i><b>1.2.1</b> The Bernoulli distribution</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#the-binomial-distribution"><i class="fa fa-check"></i><b>1.2.2</b> The binomial distribution</a></li>
<li class="chapter" data-level="1.2.3" data-path="index.html"><a href="index.html#the-negative-binomial-distribution"><i class="fa fa-check"></i><b>1.2.3</b> The negative binomial distribution</a></li>
<li class="chapter" data-level="1.2.4" data-path="index.html"><a href="index.html#poisson"><i class="fa fa-check"></i><b>1.2.4</b> The Poisson distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#examples-of-continuous-distributions"><i class="fa fa-check"></i><b>1.3</b> Examples of continuous distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#the-exponential-distribution"><i class="fa fa-check"></i><b>1.3.1</b> The exponential distribution</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#the-uniform-distribution"><i class="fa fa-check"></i><b>1.3.2</b> The uniform distribution</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#the-normal-distribution"><i class="fa fa-check"></i><b>1.3.3</b> The normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="moments.html"><a href="moments.html"><i class="fa fa-check"></i><b>2</b> Moments</a><ul>
<li class="chapter" data-level="2.1" data-path="moments.html"><a href="moments.html#expected-value"><i class="fa fa-check"></i><b>2.1</b> Expected value</a></li>
<li class="chapter" data-level="2.2" data-path="moments.html"><a href="moments.html#variance"><i class="fa fa-check"></i><b>2.2</b> Variance</a></li>
<li class="chapter" data-level="2.3" data-path="moments.html"><a href="moments.html#higher-order-moments"><i class="fa fa-check"></i><b>2.3</b> Higher-order moments</a></li>
<li class="chapter" data-level="2.4" data-path="moments.html"><a href="moments.html#standardised-moments"><i class="fa fa-check"></i><b>2.4</b> Standardised moments</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="genfuns.html"><a href="genfuns.html"><i class="fa fa-check"></i><b>3</b> Generating functions</a><ul>
<li class="chapter" data-level="3.1" data-path="genfuns.html"><a href="genfuns.html#the-moment-generating-function"><i class="fa fa-check"></i><b>3.1</b> The moment generating function</a></li>
<li class="chapter" data-level="3.2" data-path="genfuns.html"><a href="genfuns.html#the-cumulant-generating-function"><i class="fa fa-check"></i><b>3.2</b> The cumulant generating function</a></li>
<li class="chapter" data-level="3.3" data-path="genfuns.html"><a href="genfuns.html#generating-functions-under-linear-transformation"><i class="fa fa-check"></i><b>3.3</b> Generating functions under linear transformation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sums-of-random-variables.html"><a href="sums-of-random-variables.html"><i class="fa fa-check"></i><b>4</b> Sums of random variables</a><ul>
<li class="chapter" data-level="4.1" data-path="sums-of-random-variables.html"><a href="sums-of-random-variables.html#generating-functions-of-a-sum"><i class="fa fa-check"></i><b>4.1</b> Generating functions of a sum</a></li>
<li class="chapter" data-level="4.2" data-path="sums-of-random-variables.html"><a href="sums-of-random-variables.html#closure-results-for-some-standard-distributions"><i class="fa fa-check"></i><b>4.2</b> Closure results for some standard distributions</a></li>
<li class="chapter" data-level="4.3" data-path="sums-of-random-variables.html"><a href="sums-of-random-variables.html#properties-of-the-sample-mean-of-normal-observations"><i class="fa fa-check"></i><b>4.3</b> Properties of the sample mean of normal observations</a></li>
<li class="chapter" data-level="4.4" data-path="sums-of-random-variables.html"><a href="sums-of-random-variables.html#clt"><i class="fa fa-check"></i><b>4.4</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html"><i class="fa fa-check"></i><b>5</b> Maxima and minima</a><ul>
<li class="chapter" data-level="5.1" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html#order-statistics"><i class="fa fa-check"></i><b>5.1</b> Order Statistics</a></li>
<li class="chapter" data-level="5.2" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html#the-cdf-of-y_n-the-largest-value-in-a-random-sample-of-size-n"><i class="fa fa-check"></i><b>5.2</b> The cdf of <span class="math inline">\(Y_{(n)}\)</span>, the largest value in a random sample of size <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="5.3" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html#the-pdf-of-the-maximum-in-the-continuous-case"><i class="fa fa-check"></i><b>5.3</b> The pdf of the maximum in the continuous case</a></li>
<li class="chapter" data-level="5.4" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html#the-cdf-of-y_1-the-smallest-value-in-a-random-sample-of-size-n"><i class="fa fa-check"></i><b>5.4</b> The cdf of <span class="math inline">\(Y_{(1)}\)</span>, the smallest value in a random sample of size <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="5.5" data-path="maxima-and-minima.html"><a href="maxima-and-minima.html#the-pdf-of-the-minimum-in-the-continuous-case"><i class="fa fa-check"></i><b>5.5</b> The pdf of the minimum in the continuous case</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gamma.html"><a href="gamma.html"><i class="fa fa-check"></i><b>6</b> The gamma distribution</a><ul>
<li class="chapter" data-level="6.1" data-path="gamma.html"><a href="gamma.html#the-gamma-distribution"><i class="fa fa-check"></i><b>6.1</b> The gamma distribution</a></li>
<li class="chapter" data-level="6.2" data-path="gamma.html"><a href="gamma.html#properties-of-the-gamma-distribution"><i class="fa fa-check"></i><b>6.2</b> Properties of the gamma distribution</a></li>
<li class="chapter" data-level="6.3" data-path="gamma.html"><a href="gamma.html#chisquared"><i class="fa fa-check"></i><b>6.3</b> The chi-squared distribution</a></li>
<li class="chapter" data-level="6.4" data-path="gamma.html"><a href="gamma.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>6.4</b> Distribution of the sample variance</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="unitransform.html"><a href="unitransform.html"><i class="fa fa-check"></i><b>7</b> Univariate transformations</a><ul>
<li class="chapter" data-level="7.1" data-path="unitransform.html"><a href="unitransform.html#transformed-random-variables"><i class="fa fa-check"></i><b>7.1</b> Transformed random variables</a></li>
<li class="chapter" data-level="7.2" data-path="unitransform.html"><a href="unitransform.html#one-to-one-transformations-of-continuous-random-variables"><i class="fa fa-check"></i><b>7.2</b> One-to-one transformations of continuous random variables</a></li>
<li class="chapter" data-level="7.3" data-path="unitransform.html"><a href="unitransform.html#generating-samples-from-any-distribution"><i class="fa fa-check"></i><b>7.3</b> Generating samples from any distribution</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html"><i class="fa fa-check"></i><b>8</b> Bivariate distributions</a><ul>
<li class="chapter" data-level="8.1" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html#joint-distributions"><i class="fa fa-check"></i><b>8.1</b> Joint distributions</a></li>
<li class="chapter" data-level="8.2" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html#moments-of-jointly-distributed-random-variables"><i class="fa fa-check"></i><b>8.2</b> Moments of jointly distributed random variables</a></li>
<li class="chapter" data-level="8.3" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html#the-bivariate-normal-distribution"><i class="fa fa-check"></i><b>8.3</b> The bivariate normal distribution</a></li>
<li class="chapter" data-level="8.4" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html#bivariate-moment-generating-functions"><i class="fa fa-check"></i><b>8.4</b> Bivariate moment generating functions</a></li>
<li class="chapter" data-level="8.5" data-path="bivariate-distributions.html"><a href="bivariate-distributions.html#a-useful-property-of-covariances"><i class="fa fa-check"></i><b>8.5</b> A useful property of covariances</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html"><i class="fa fa-check"></i><b>9</b> Bivariate transformations</a><ul>
<li class="chapter" data-level="9.1" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html#the-transformation-theorem"><i class="fa fa-check"></i><b>9.1</b> The transformation theorem</a></li>
<li class="chapter" data-level="9.2" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html#the-beta-distribution"><i class="fa fa-check"></i><b>9.2</b> The beta distribution</a></li>
<li class="chapter" data-level="9.3" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html#the-cauchy-distribution"><i class="fa fa-check"></i><b>9.3</b> The Cauchy distribution</a></li>
<li class="chapter" data-level="9.4" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html#the-t-distribution"><i class="fa fa-check"></i><b>9.4</b> The <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="9.5" data-path="bivariate-transformations.html"><a href="bivariate-transformations.html#the-f-distribution"><i class="fa fa-check"></i><b>9.5</b> The <span class="math inline">\(F\)</span> distribution</a></li>
</ul></li>
<li class="part"><span><b>II Statistical inference</b></span></li>
<li class="chapter" data-level="10" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>10</b> Parameter estimation</a><ul>
<li class="chapter" data-level="10.1" data-path="estimation.html"><a href="estimation.html#estimators-and-estimates"><i class="fa fa-check"></i><b>10.1</b> Estimators and estimates</a></li>
<li class="chapter" data-level="10.2" data-path="estimation.html"><a href="estimation.html#bias"><i class="fa fa-check"></i><b>10.2</b> Bias</a></li>
<li class="chapter" data-level="10.3" data-path="estimation.html"><a href="estimation.html#consistency"><i class="fa fa-check"></i><b>10.3</b> Consistency</a></li>
<li class="chapter" data-level="10.4" data-path="estimation.html"><a href="estimation.html#mean-squared-error"><i class="fa fa-check"></i><b>10.4</b> Mean squared error</a></li>
<li class="chapter" data-level="10.5" data-path="estimation.html"><a href="estimation.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>10.5</b> Method of moments estimation</a></li>
<li class="chapter" data-level="10.6" data-path="estimation.html"><a href="estimation.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>10.6</b> Maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>11</b> Confidence intervals and hypothesis testing</a><ul>
<li class="chapter" data-level="11.1" data-path="inference.html"><a href="inference.html#expressing-uncertainty-in-parameter-estimates"><i class="fa fa-check"></i><b>11.1</b> Expressing uncertainty in parameter estimates</a></li>
<li class="chapter" data-level="11.2" data-path="inference.html"><a href="inference.html#confidence-intervals"><i class="fa fa-check"></i><b>11.2</b> Confidence intervals</a></li>
<li class="chapter" data-level="11.3" data-path="inference.html"><a href="inference.html#hypothesis-testing"><i class="fa fa-check"></i><b>11.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="11.4" data-path="inference.html"><a href="inference.html#two-sample-hypothesis-testing"><i class="fa fa-check"></i><b>11.4</b> Two-sample hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>12</b> Bayesian inference</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian.html"><a href="bayesian.html#frequentist-and-bayesian-inference"><i class="fa fa-check"></i><b>12.1</b> Frequentist and Bayesian inference</a></li>
<li class="chapter" data-level="12.2" data-path="bayesian.html"><a href="bayesian.html#prior-and-posterior-distributions"><i class="fa fa-check"></i><b>12.2</b> Prior and posterior distributions</a></li>
<li class="chapter" data-level="12.3" data-path="bayesian.html"><a href="bayesian.html#the-posterior-predictive-distribution"><i class="fa fa-check"></i><b>12.3</b> The posterior predictive distribution</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH2011: Statistical Distribution Theory</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\(
\newcommand{\bm}[1]{\boldsymbol{\mathbf{#1}}}
\)
<div id="header">
<h1 class="title">MATH2011: Statistical Distribution Theory</h1>
<p class="author"><em>Dr Helen Ogden</em></p>
<p class="date"><em>2019/20</em></p>
</div>
<div id="probability-distributions" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Probability distributions</h1>

<div id="random-variables" class="section level2">
<h2><span class="header-section-number">1.1</span> Random variables</h2>
<p>A random variable <span class="math inline">\(Y\)</span> is described by its domain (or sample space) <span class="math inline">\(D\)</span> together with the probabilities assigned to subsets of the domain. These define the <em>probability distribution</em> of the random variable. We distinguish between discrete and continuous random variables.</p>
<p><strong>Discrete</strong> probability distributions are defined by a probability (mass) function <span class="math display">\[p(y)\equiv P(Y=y), \quad \text{for $y \in D$}\]</span> where <span class="math display">\[\sum_{y\in D} p(y) =1.\]</span> The distribution function <span class="math inline">\(F(\cdot)\)</span> is defined for all <span class="math inline">\(y \in \mathbb{R}\)</span> by <span class="math display">\[F(y)\equiv P(Y \leq y) = \sum_{x\in D: \, x\leq y} p(x).\]</span></p>
<p><strong>Continuous</strong> probability distributions are defined by a probability density function (pdf) <span class="math inline">\(f(\cdot)\)</span> where <span class="math display">\[P(y_1&lt; Y \leq y_2) = \int_{y_1}^{y_2} f(y) dy.\]</span> The domain of <span class="math inline">\(Y\)</span> is the set <span class="math inline">\(D = \{y \in \mathbb{R}: f(y) &gt; 0\}\)</span> Hence <span class="math display">\[\int_{-\infty}^\infty f(y) dy = \int_D f(y) dy = 1.\]</span> The distribution function <span class="math inline">\(F(\cdot)\)</span> is then given by <span class="math display">\[F(y)\equiv P(Y \leq y) = \int_{-\infty}^y f(x) dx.\]</span> Therefore <span class="math display">\[P(y_1&lt; Y \leq y_2) = F(y_2) - F(y_1)\]</span> and <span class="math display">\[f(y) = \frac{d}{dy} F(y).\]</span></p>
</div>
<div id="examples-of-discrete-distributions" class="section level2">
<h2><span class="header-section-number">1.2</span> Examples of discrete distributions</h2>
<div id="the-bernoulli-distribution" class="section level3">
<h3><span class="header-section-number">1.2.1</span> The Bernoulli distribution</h3>
<p>A <em>Bernoulli trial</em> is an experiment with just two possible outcomes ‘success’ and ‘failure’ which occur with probabilities <span class="math inline">\(\theta\)</span> and <span class="math inline">\(1- \theta\)</span> respectively, where <span class="math inline">\(\theta\)</span> is the success probability. The indicator of success in a Bernoulli trial has Bernoulli distribution.</p>

<div class="definition">
<span id="def:unnamed-chunk-1" class="definition"><strong>Definition 1.1  </strong></span>A discrete random variables <span class="math inline">\(Y\)</span> has <em>Bernoulli</em> distribution if it has probability function of the form <span class="math display">\[p(y) = \theta^y (1- \theta)^{1-y}, \quad y = 0, 1,\]</span> for some <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>. We write <span class="math inline">\(Y \sim \text{Bernoulli}(\theta)\)</span>.
</div>

</div>
<div id="the-binomial-distribution" class="section level3">
<h3><span class="header-section-number">1.2.2</span> The binomial distribution</h3>
<p>Suppose we undertake a fixed number, <span class="math inline">\(n\)</span>, of independent Bernoulli trials, each with success probability <span class="math inline">\(\theta\)</span>. Let <span class="math inline">\(Y\)</span> be the number of successes in these <span class="math inline">\(n\)</span> trials. Then <span class="math inline">\(Y\)</span> has <em>binomial</em> distribution.</p>

<div class="definition">
<span id="def:unnamed-chunk-2" class="definition"><strong>Definition 1.2  </strong></span>A discrete random variables <span class="math inline">\(Y\)</span> has <em>binomial</em> distribution if it has probability function of the form <span class="math display">\[p(y) = \binom{n}{y} \theta^x (1 - \theta)^{n-y}, \quad y = 0, 1, \ldots, n,\]</span> for some <span class="math inline">\(n \in \mathbb{N}\)</span> and <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>. We write <span class="math inline">\(Y \sim \text{binomial}(n, \theta)\)</span>.
</div>

</div>
<div id="the-negative-binomial-distribution" class="section level3">
<h3><span class="header-section-number">1.2.3</span> The negative binomial distribution</h3>
Suppose we undertake a sequence of independent Bernoulli trials, each with success probability <span class="math inline">\(\theta\)</span>. Let <span class="math inline">\(X\)</span> be the number failures that occur before the <span class="math inline">\(k\)</span>th success. Then <span class="math inline">\(X\)</span> has <em>negative binomial</em> distribution. 
<div class="definition">
<span id="def:unnamed-chunk-3" class="definition"><strong>Definition 1.3  </strong></span>A discrete random variables <span class="math inline">\(Y\)</span> has <em>negative binomial</em> distribution if it has probability function of the form <span class="math display">\[p(y) = \binom{k + y - 1}{y} (1 - \theta)^y \theta^k, \quad
  y = 0, 1, \ldots,
\]</span> for some <span class="math inline">\(k \in \mathbb{N}\)</span>, and <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>. We write <span class="math inline">\(Y \sim \text{negbin}(k, \theta)\)</span>.
</div>

<p>The <em>geometric</em> distribution is the special case of the negative binomial distribution with <span class="math inline">\(k = 1\)</span>: the number of failures that occur before the first success.</p>

<div class="definition">
<span id="def:unnamed-chunk-4" class="definition"><strong>Definition 1.4  </strong></span>A discrete random variables <span class="math inline">\(Y\)</span> has <em>geometric</em> distribution if it has probability function of the form <span class="math display">\[p(y) = (1 - \theta)^y \theta, \quad
  y = 0, 1, \ldots,
\]</span> for some <span class="math inline">\(0 &lt; \theta &lt; 1\)</span>. We write <span class="math inline">\(Y \sim \text{geometric}(\theta)\)</span>.
</div>

</div>
<div id="poisson" class="section level3">
<h3><span class="header-section-number">1.2.4</span> The Poisson distribution</h3>
<p>The <em>Poisson</em> distribution arises in a variety of practical situations where we are interested in modelling counts of how often an ‘event’ occurs.</p>

<div class="definition">
<span id="def:unnamed-chunk-5" class="definition"><strong>Definition 1.5  </strong></span>A discrete random variable <span class="math inline">\(Y\)</span> has <em>Poisson</em> distribution if it has probability function of the form <span class="math display">\[p(y) = \frac{e^{-\theta} (\theta)^y}{y!}, \quad y = 0, 1, \ldots,\]</span> for some <em>rate parameter</em> <span class="math inline">\(\theta &gt; 0\)</span>. We write <span class="math inline">\(Y \sim \text{Poisson}(\theta)\)</span>.
</div>

<p>In a <em>Poisson process</em>, events occur at random at constant rate <span class="math inline">\(\theta\)</span> per unit time, independent of all other events. If we define <span class="math inline">\(Y\)</span> as the number of events of a Poisson process in an interval of fixed length <span class="math inline">\(t\)</span>, then <span class="math inline">\(Y \sim \text{Poisson}(t \theta)\)</span>.</p>

</div>
</div>
<div id="examples-of-continuous-distributions" class="section level2">
<h2><span class="header-section-number">1.3</span> Examples of continuous distributions</h2>
<div id="the-exponential-distribution" class="section level3">
<h3><span class="header-section-number">1.3.1</span> The exponential distribution</h3>
<p>In Section <a href="index.html#poisson">1.2.4</a>, we considered the Poisson process, in which events occur at random, at a rate <span class="math inline">\(\theta\)</span> per unit time. The actual number of events which take place in any given unit of time has <span class="math inline">\(\text{Poisson}(\theta)\)</span> distribution. The <em>exponential</em> distribution represents the time between consecutive events in this process.</p>
Let <span class="math inline">\(Y\)</span> represent the time interval between two events. Clearly this variable cannot be negative, but can take any positive value. The domain of <span class="math inline">\(Y\)</span> is <span class="math inline">\((0, \infty)\)</span>. We have
<span class="math display">\[\begin{align*}
P(Y &gt; y) &amp;= P(\text{no events in an interval of length $y$}) \\
&amp;= \frac{e^{-\theta y} (\theta y)^0}{0!} \\
&amp;= e^{-\theta y}
\end{align*}\]</span>
<p>so <span class="math display">\[F(y) = P(Y \leq y) = 1 - e^{-\theta y}, \quad y &gt; 0.\]</span> Differentiating, we obtain the pdf <span class="math display">\[f(y) = \frac{d}{dy} F(y) = \theta e^{-\theta y}, \quad y &gt; 0.\]</span></p>

<div class="definition">
<span id="def:unnamed-chunk-6" class="definition"><strong>Definition 1.6  </strong></span>A random variable <span class="math inline">\(Y\)</span> has <em>exponential</em> distribution if it has pdf of the form <span class="math display">\[f(y) = \theta e^{-\theta y}, \quad y &gt; 0,\]</span> for some <em>rate parameter</em> <span class="math inline">\(\theta &gt; 0\)</span>. We write <span class="math inline">\(Y \sim \text{exponential}(\theta)\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-7" class="example"><strong>Example 1.1  </strong></span> Suppose the lifetime in hours of a certain type of electronic component is described by an Exponential random variable with rate parameter <span class="math inline">\(\theta = 0.01\)</span>. What is the probability such a component will have a lifetime of between <span class="math inline">\(100\)</span> and <span class="math inline">\(200\)</span> hours?</p>
The probability is the area under the curve <span class="math inline">\(f(y) = 0.01 e^{-0.01 y}\)</span> between <span class="math inline">\(y = 100\)</span> and <span class="math inline">\(y = 200\)</span>, so
<span class="math display">\[\begin{align*}
P(100 &lt; Y \leq 200) &amp;= \int_{100}^{200} 0.01e^{-0.01 y} dy \\
&amp;= e^{-1} - e^{-2} = 0.37 - 0.14 = 0.23.
\end{align*}\]</span>
</div>
<p> We could find this in <code>R</code> with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pexp</span>(<span class="dv">200</span>, <span class="dt">rate =</span> <span class="fl">0.01</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pexp</span>(<span class="dv">100</span>, <span class="dt">rate =</span> <span class="fl">0.01</span>)</code></pre></div>
<pre><code>## [1] 0.2325442</code></pre>
</div>
<div id="the-uniform-distribution" class="section level3">
<h3><span class="header-section-number">1.3.2</span> The uniform distribution</h3>
<p>The uniform distribution is one of the simplest probability distributions: it just places a constant density between some range <span class="math inline">\((a, b)\)</span>:</p>

<div class="definition">
<span id="def:unnamed-chunk-9" class="definition"><strong>Definition 1.7  </strong></span>A random variable <span class="math inline">\(Y\)</span> has <em>uniform</em> distribution if it has pdf of the form <span class="math display">\[f(y) = \frac{1}{b-a}, a &lt; y &lt; b,\]</span> for some parameters <span class="math inline">\(a, b \in \mathbb{R}\)</span>, with <span class="math inline">\(b &gt; a\)</span>. We write <span class="math inline">\(Y \sim U(a, b)\)</span>.
</div>

</div>
<div id="the-normal-distribution" class="section level3">
<h3><span class="header-section-number">1.3.3</span> The normal distribution</h3>
<p>The normal distribution is probably the single most important distribution in statistics. The main reason for its importance is the central limit theorem, which you have seen before in MATH1024, and which we will prove in Section <a href="sums-of-random-variables.html#clt">4.4</a>.</p>

<div class="definition">
<span id="def:unnamed-chunk-10" class="definition"><strong>Definition 1.8  </strong></span>A random variable <span class="math inline">\(Y\)</span> has <em>normal</em> distribution if it has pdf of the form <span class="math display">\[f(y) = \frac{1}{\sqrt{2 \pi \sigma^2}}
\exp\left\{-\frac{1}{2 \sigma^2} (y - \mu)^2 \right\},\]</span> for some parameters <span class="math inline">\(\mu \in \mathbb{R}\)</span> and <span class="math inline">\(\sigma^2 &gt; 0\)</span>. We write <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-11" class="example"><strong>Example 1.2  </strong></span>Suppose that daily water use at a factory varies about a mean of <span class="math inline">\(77500\)</span> litres with standard deviation <span class="math inline">\(5700\)</span> litres. If demand is normally distributed</p>
<ol style="list-style-type: decimal">
<li>What proportion of days does the demand fall short of <span class="math inline">\(70000\)</span> litres?</li>
<li>What proportion of days does demand exceed <span class="math inline">\(90000\)</span> litres?</li>
<li>What is your reaction to a demand of <span class="math inline">\(175000\)</span> gallons?</li>
</ol>
Writing <span class="math inline">\(X\)</span> for the daily water use in litres , we have <span class="math inline">\(X \sim N(77500, 5700^2)\)</span> We can use <code>R</code> to compute the probability <span class="math inline">\(P(X &lt; 70000) = F(70000)\)</span>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dv">70000</span>, <span class="dt">mean =</span> <span class="dv">77500</span>, <span class="dt">sd =</span> <span class="dv">5700</span>)</code></pre></div>
<pre><code>## [1] 0.09412236</code></pre>
<p>so the daily water use will be less than <span class="math inline">\(70000\)</span> litres about <span class="math inline">\(9.4\%\)</span> of the time.</p>
<p>We can find <span class="math inline">\(P(x &gt; 90000) = 1 - F(90000)\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">90000</span>, <span class="dt">mean =</span> <span class="dv">77500</span>, <span class="dt">sd =</span> <span class="dv">5700</span>)</code></pre></div>
<pre><code>## [1] 0.01415432</code></pre>
<p>so the daily water use will be more than <span class="math inline">\(90000\)</span> litres about <span class="math inline">\(1.4\%\)</span> of the time.</p>
<p>We can find <span class="math inline">\(P(x &gt; 175000) = 1 - F(175000)\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">175000</span>, <span class="dt">mean =</span> <span class="dv">77500</span>, <span class="dt">sd =</span> <span class="dv">5700</span>)</code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>In fact, the number is not exactly zero, but it is so small that the computer is rounding it to zero. Such an extreme water use is therefore surprising, and an explanation should be sought. It is possible that a error has occurred in recording the water use, such as two days data being taken together. Alternatively, perhaps our model which assumes that <span class="math inline">\(X \sim N(77500, 5700^2)\)</span> is incorrect. This idea of surprise at an extreme result of low probability, as predicted by a statistical model, will be important later in this module and also in modules such as MATH2010 Statistical Modelling I.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="moments.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/heogden/math2011/edit/master/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["MATH2011.pdf", "MATH2011.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
