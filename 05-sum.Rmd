# (PART) Transformations of distributions {-}

# Distribution of a sum of rvs

## Motivation
In many situations in Statistics we end up with situations 
where we are interested in understanding the properties of 
(possibly weighted) sums of random variables.
For example, the sample mean is frequently used as a summary 
measure for a set of observations and it is simply a weighted 
sum of the observations (each observation has weight $1/n$, 
where $n$ is the number of observations).
Either through good fortune or by design the random variables 
are often independent. In this chapter we consider sums of 
independent random variables. 

##  Mgf and cgf of a sum of independent rvs {#gensum}
Suppose that $Y_1$ and $Y_2$ are independent random variables 
with moment generating functions 
$M_{Y_1}(t)$ and $M_{Y_2}$.
Let $Z = Y_1 + Y_2.$
Then $Z$ has mgf
\[M_Z(t)  = M_{Y_1}(t) M_{Y_2}(t).\]

```{proof}
**[TODO: add proof]**
```

In general, for independent rvs
$Y_1, Y_2, \ldots Y_n$ 
with moment generating
functions $M_{Y_i}(t)$ , $i = 1, 2, \ldots, n$,
$Z = \sum_{i=1}^n Y_i$ 
has moment generating function
\[M_Z(t) = \prod_{i=1}^n M_{Y_i}(t).\]

A special case of this is that if $Y_1, Y_2, \ldots Y_n$  all have
the same distribution with moment generating function $M_Y(t)$,
then
$M_Z(t) = [M_Y(t)]^n$.

Similarly, for independent rvs
$Y_1, Y_2, \ldots Y_n$ 
with cumulant generating
functions $K_{Y_i}(t)$ , $i = 1, 2, \ldots, n$,
$Z = \sum_{i=1}^n Y_i$ 
has moment generating function
\[K_Z(t) = \sum_{i=1}^n K_{Y_i}(t).\]

```{proof}
**[TODO: add proof]**
```

## Closure results for some standard types of random variables

Using the results of Section \@ref(gensum)
we get some very useful “closure”
results for sums of independent rvs.

| Distribution      | $Y_i$                          | $Z$                                              |
|----|----|----|
| Binomial          | $\text{Binomial}(n_i, \theta)$ | $\text{Binomial}(\sum_{i=1}^n n_i, \theta)$      |
| Negative binomial | $\text{NegBin}(k_i, \theta)$   | $\text{NegBin}(\sum_{i=1}^n k_i, \theta)$        |
| Poisson           | $\text{Poisson}(\theta_i)$     | $\text{Poisson}(\sum_{i=1}^n \theta_i)$          |
| Normal            | $N(\mu_i, \sigma^2_i)$         | $N(\sum_{i=1}^n \mu_i, \sum_{i=1}^n \sigma^2_i)$ |

Table: (\#tab:closure) Some distributions with closure properties under summation

**TODO: fix formatting of this table (in PDF)**

We shall illustrate two of these results and leave the others as exercises.

```{example, name = "Sum of independent Binomial rvs with common success probability"}

Suppose that $Y_1, \ldots, Y_n$
are independent, with $Y_i \sim \text{Binomial}(n_i , \theta)$. Then
$Z = \sum_{i=1}^n Y_i \sim \text{Binomial}(\sum_{i=1}^n n_i, \theta)$.

**TODO: proof**


As a corollary, note that if the 
$Y_i$ are independent $\text{Bernoulli}(\theta)$ rvs, then 
$Z \sim \text{Binomial}(n, \theta)$.
```

```{example, name = "Sum of independent normal rvs"}

Suppose that $Y_1, \ldots, Y_n$
are independent, with $Y_i \sim N(\mu, \sigma^2)$. Then
$Z = \sum_{i=1}^n Y_i \sim N(\sum_{i=1}^n \mu_i, \sum_{i=1}^n \sigma^2)$.

**TODO: proof**

As a corollary, note that if the 
$Y_i$ are independent $N(\mu, \sigma^2)$ rvs, then 
$Z \sim N(n \mu, n \sigma^2)$.
```

## Properties of the sample mean of normal observations

Suppose that $Y_1, \ldots, Y_n$  are independent
and identically distributed,
with $Y_i \sim N(\mu, \sigma^2)$, and let
\[\bar Y = \frac{\sum_{i=1}^n Y_i}{n}\]
be the sample mean.

What is the distribution of $\bar Y$?

For each $Y_i$, the cgf is 
$K_{Y_i}(t) = \mu t + \frac{1}{2} \sigma^2 t^2$
(see Example **TODO: insert reference**).

We use the properties of cgfs to derive the well-known result 
$\bar Y \sim N(\mu, \sigma^2/n)$.

**TODO: add proof**


## The central limit theorem (CLT)

```{theorem}
Suppose that $Y_1, \ldots, Y_n$  are independent
and identically distributed,
each with finite variance and $r$th cumulant $\kappa_r$.
Let
\[Z = \frac{\bar Y - \kappa_1}{\sqrt{\kappa_2}/n}\]
(here $\kappa_1 = E(Y)$ and $\kappa_2 = \text{Var}(Y)$
**TODO: should we rephrase the CLT in terms of $\mu$
and $\sigma^2$?**).
Then $Z \rightarrow N(0, 1)$ as $n \rightarrow \infty$.
```

```{remark}
Note that (see Example **TODO: add reference**) a
$N(0, 1)$ rv has second cumulant $1$ and all other
cumulants are $0$. So in our sketch proof, we aim to show that the
cumulants of $Z$ have the same structure as $n \rightarrow \infty$.
```
```{proof}
**TODO: add sketch proof**
```
